{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”¬ èƒšèƒè‘—åºŠé æ¸¬ - EfficientNet æ¨¡å‹è¨“ç·´\n",
    "\n",
    "> EXP-002: ä½¿ç”¨ EfficientNet-B0 æ”¹é€²æ¨¡å‹æ•ˆèƒ½\n",
    "\n",
    "**ç›®æ¨™**ï¼šæ¯”è¼ƒ EfficientNet-B0 èˆ‡ ResNet18 (EXP-001) çš„æ•ˆèƒ½å·®ç•°\n",
    "\n",
    "**æ”¹å‹•**ï¼šåƒ…æ›´æ›æ¨¡å‹æ¶æ§‹ï¼Œå…¶ä»–è¨­å®šä¿æŒä¸€è‡´\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ç’°å¢ƒè¨­ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ›è¼‰ Google Driveï¼ˆå¦‚æœåœ¨ Colab ä¸ŠåŸ·è¡Œï¼‰\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"âœ… Google Drive å·²æ›è¼‰\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ ä¸åœ¨ Colab ç’°å¢ƒï¼Œè·³éæ›è¼‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŒ¯å…¥å¥—ä»¶\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score, \n",
    "    recall_score, f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# è¨­å®šéš¨æ©Ÿç¨®å­ï¼ˆç¢ºä¿å¯é‡ç¾ï¼Œèˆ‡ EXP-001 ä¸€è‡´ï¼‰\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# æª¢æŸ¥ GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ğŸ–¥ï¸ ä½¿ç”¨è£ç½®: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ è¨­å®šè³‡æ–™è·¯å¾‘\n",
    "\n",
    "âš ï¸ **è«‹æ ¹æ“šä½ çš„è³‡æ–™ä½ç½®ä¿®æ”¹ä¸‹æ–¹è·¯å¾‘**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# âš ï¸ è«‹ä¿®æ”¹é€™è£¡çš„è·¯å¾‘ï¼\n",
    "# =============================================\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Colabï¼šè³‡æ–™åœ¨ Google Drive ä¸­\n",
    "    DATA_ROOT = '/content/drive/MyDrive/hvwc23'  # â† ä¿®æ”¹æˆä½ çš„è·¯å¾‘\n",
    "else:\n",
    "    # æœ¬æ©Ÿ\n",
    "    DATA_ROOT = '../data/raw/hvwc23'\n",
    "\n",
    "# ç¢ºèªè·¯å¾‘\n",
    "TRAIN_DIR = os.path.join(DATA_ROOT, 'train')\n",
    "TEST_DIR = os.path.join(DATA_ROOT, 'test')\n",
    "TRAIN_CSV = os.path.join(DATA_ROOT, 'train.csv')\n",
    "TEST_CSV = os.path.join(DATA_ROOT, 'test.csv')\n",
    "\n",
    "# æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨\n",
    "print(\"ğŸ“ æª¢æŸ¥è³‡æ–™è·¯å¾‘...\")\n",
    "print(f\"   è¨“ç·´è³‡æ–™å¤¾: {os.path.exists(TRAIN_DIR)} - {TRAIN_DIR}\")\n",
    "print(f\"   æ¸¬è©¦è³‡æ–™å¤¾: {os.path.exists(TEST_DIR)} - {TEST_DIR}\")\n",
    "print(f\"   è¨“ç·´ CSV:   {os.path.exists(TRAIN_CSV)} - {TRAIN_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ è¼‰å…¥è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥æ¨™ç±¤\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "print(f\"ğŸ“Š è¨“ç·´è³‡æ–™ç­†æ•¸: {len(train_df)}\")\n",
    "\n",
    "# é¡åˆ¥åˆ†ä½ˆ\n",
    "print(\"\\nğŸ“Š é¡åˆ¥åˆ†ä½ˆ:\")\n",
    "class_counts = train_df['Class'].value_counts().sort_index()\n",
    "for cls, count in class_counts.items():\n",
    "    pct = count / len(train_df) * 100\n",
    "    label = \"ä¸æœƒè‘—åºŠ\" if cls == 0 else \"æœƒè‘—åºŠ\"\n",
    "    print(f\"   Class {cls} ({label}): {count} å¼µ ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ è³‡æ–™å‰è™•ç†ï¼ˆèˆ‡ EXP-001 ç›¸åŒï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†å‰²è¨“ç·´é›†å’Œé©—è­‰é›†ï¼ˆ80/20ï¼Œåˆ†å±¤æŠ½æ¨£ï¼‰\n",
    "# âš ï¸ ä½¿ç”¨ç›¸åŒçš„ SEEDï¼Œç¢ºä¿åˆ†å‰²çµæœèˆ‡ EXP-001 ä¸€è‡´\n",
    "train_data, val_data = train_test_split(\n",
    "    train_df, \n",
    "    test_size=0.2, \n",
    "    random_state=SEED, \n",
    "    stratify=train_df['Class']\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š è³‡æ–™åˆ†å‰²çµæœ:\")\n",
    "print(f\"   è¨“ç·´é›†: {len(train_data)} å¼µ\")\n",
    "print(f\"   é©—è­‰é›†: {len(val_data)} å¼µ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šç¾©è³‡æ–™å¢å¼·èˆ‡è½‰æ›ï¼ˆèˆ‡ EXP-001 ç›¸åŒï¼‰\n",
    "IMG_SIZE = 224\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "print(\"âœ… è³‡æ–™è½‰æ›å®šç¾©å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‡ªå®šç¾© Dataset\n",
    "class EmbryoDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['Image'])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = row['Class']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# å»ºç«‹ Dataset\n",
    "train_dataset = EmbryoDataset(train_data, TRAIN_DIR, train_transform)\n",
    "val_dataset = EmbryoDataset(val_data, TRAIN_DIR, val_transform)\n",
    "\n",
    "print(f\"âœ… Dataset å»ºç«‹å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹ DataLoader\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"âœ… DataLoader å»ºç«‹å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ å»ºç«‹æ¨¡å‹ï¼ˆEfficientNet-B0ï¼‰\n",
    "\n",
    "ğŸ”„ **é€™æ˜¯èˆ‡ EXP-001 çš„ä¸»è¦å·®ç•°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# ğŸ”„ ä½¿ç”¨ EfficientNet-B0ï¼ˆèˆ‡ EXP-001 ä¸åŒï¼‰\n",
    "# =============================================\n",
    "\n",
    "model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "\n",
    "# ä¿®æ”¹æœ€å¾Œä¸€å±¤ï¼ˆEfficientNet çš„åˆ†é¡å™¨çµæ§‹ä¸åŒï¼‰\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_features, 2)\n",
    "\n",
    "# ç§»åˆ° GPU\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"âœ… æ¨¡å‹å»ºç«‹å®Œæˆ: EfficientNet-B0\")\n",
    "print(f\"   åƒæ•¸é‡: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   å¯è¨“ç·´åƒæ•¸: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "print()\n",
    "print(\"ğŸ“Š èˆ‡ ResNet18 æ¯”è¼ƒ:\")\n",
    "print(\"   ResNet18:      11,689,512 åƒæ•¸\")\n",
    "print(f\"   EfficientNet:  {sum(p.numel() for p in model.parameters()):,} åƒæ•¸\")\n",
    "print(f\"   â†’ åƒæ•¸æ¸›å°‘ç´„ {(1 - sum(p.numel() for p in model.parameters()) / 11689512) * 100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨ˆç®—é¡åˆ¥æ¬Šé‡ï¼ˆèˆ‡ EXP-001 ç›¸åŒï¼‰\n",
    "class_counts = train_data['Class'].value_counts().sort_index()\n",
    "total = len(train_data)\n",
    "class_weights = torch.tensor([total / (2 * class_counts[i]) for i in range(2)], dtype=torch.float32)\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "print(f\"ğŸ“Š é¡åˆ¥æ¬Šé‡:\")\n",
    "print(f\"   Class 0: {class_weights[0]:.4f}\")\n",
    "print(f\"   Class 1: {class_weights[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šç¾©æå¤±å‡½æ•¸å’Œå„ªåŒ–å™¨ï¼ˆèˆ‡ EXP-001 ç›¸åŒï¼‰\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "print(\"âœ… è¨“ç·´è¨­å®šå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ è¨“ç·´æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´å‡½æ•¸\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(loader), correct / total\n",
    "\n",
    "# é©—è­‰å‡½æ•¸\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "    except:\n",
    "        auc = 0.0\n",
    "    \n",
    "    return running_loss / len(loader), accuracy, auc, all_preds, all_probs, all_labels\n",
    "\n",
    "print(\"âœ… è¨“ç·´å‡½æ•¸å®šç¾©å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é–‹å§‹è¨“ç·´\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': [], 'val_auc': []\n",
    "}\n",
    "\n",
    "best_auc = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸš€ é–‹å§‹è¨“ç·´ EfficientNet-B0\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, val_auc, _, _, _ = validate(model, val_loader, criterion, device)\n",
    "    scheduler.step()\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_auc'].append(val_auc)\n",
    "    \n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), 'best_model_efficientnet.pth')\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:02d}/{NUM_EPOCHS} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, AUC: {val_auc:.4f}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"âœ… è¨“ç·´å®Œæˆï¼æœ€ä½³ AUC: {best_auc:.4f} (Epoch {best_epoch})\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ è¦–è¦ºåŒ–è¨“ç·´éç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¹ªè£½è¨“ç·´æ›²ç·š\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Train', marker='o', markersize=3)\n",
    "axes[0].plot(history['val_loss'], label='Validation', marker='o', markersize=3)\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history['train_acc'], label='Train', marker='o', markersize=3)\n",
    "axes[1].plot(history['val_acc'], label='Validation', marker='o', markersize=3)\n",
    "axes[1].set_title('Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(history['val_auc'], label='Validation AUC', marker='o', markersize=3, color='green')\n",
    "axes[2].axhline(y=best_auc, color='r', linestyle='--', label=f'Best: {best_auc:.4f}')\n",
    "axes[2].axhline(y=0.7986, color='blue', linestyle=':', label='EXP-001: 0.7986')\n",
    "axes[2].set_title('Validation AUC')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves_efficientnet.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ æœ€çµ‚è©•ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥æœ€ä½³æ¨¡å‹\n",
    "model.load_state_dict(torch.load('best_model_efficientnet.pth'))\n",
    "print(f\"âœ… è¼‰å…¥æœ€ä½³æ¨¡å‹ (Epoch {best_epoch})\")\n",
    "\n",
    "# æœ€çµ‚é©—è­‰\n",
    "val_loss, val_acc, val_auc, all_preds, all_probs, all_labels = validate(\n",
    "    model, val_loader, criterion, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨ˆç®—è©³ç´°æŒ‡æ¨™\n",
    "precision_1 = precision_score(all_labels, all_preds, pos_label=1)\n",
    "recall_1 = recall_score(all_labels, all_preds, pos_label=1)\n",
    "f1_1 = f1_score(all_labels, all_preds, pos_label=1)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“Š EXP-002 æœ€çµ‚è©•ä¼°çµæœ\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(f\"âœ… Accuracy:  {val_acc:.4f} ({val_acc*100:.1f}%)\")\n",
    "print(f\"âœ… AUC-ROC:   {val_auc:.4f}\")\n",
    "print(f\"âœ… Precision: {precision_1:.4f}\")\n",
    "print(f\"âœ… Recall:    {recall_1:.4f}\")\n",
    "print(f\"âœ… F1-Score:  {f1_1:.4f}\")\n",
    "print()\n",
    "print(\"ğŸ“Š èˆ‡ EXP-001 (ResNet18) æ¯”è¼ƒ:\")\n",
    "print(f\"{'æŒ‡æ¨™':<12} {'EXP-001':<10} {'EXP-002':<10} {'å·®ç•°':<10}\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'AUC':<12} {'0.7986':<10} {val_auc:<10.4f} {val_auc - 0.7986:+.4f}\")\n",
    "print(f\"{'Recall':<12} {'0.7600':<10} {recall_1:<10.4f} {recall_1 - 0.76:+.4f}\")\n",
    "print(f\"{'Precision':<12} {'0.5000':<10} {precision_1:<10.4f} {precision_1 - 0.50:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ··æ·†çŸ©é™£\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['é æ¸¬: ä¸è‘—åºŠ', 'é æ¸¬: è‘—åºŠ'],\n",
    "            yticklabels=['å¯¦éš›: ä¸è‘—åºŠ', 'å¯¦éš›: è‘—åºŠ'])\n",
    "plt.title('æ··æ·†çŸ©é™£ - EfficientNet-B0 (EXP-002)')\n",
    "plt.ylabel('å¯¦éš›å€¼')\n",
    "plt.xlabel('é æ¸¬å€¼')\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "plt.figtext(0.5, -0.05, \n",
    "            f'TN={tn} | FP={fp} | FN={fn} | TP={tp}', \n",
    "            ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_efficientnet.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ çµæœæ‘˜è¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”¢ç”Ÿçµæœæ‘˜è¦\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“‹ EXP-002 çµæœæ‘˜è¦ï¼ˆè«‹è¤‡è£½æ­¤å€å¡Šå›å ±ï¼‰\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "## å¯¦é©—è¨­å®š\n",
    "- æ¨¡å‹: EfficientNet-B0 (é è¨“ç·´)\n",
    "- è¨“ç·´é›†: {len(train_data)} å¼µ\n",
    "- é©—è­‰é›†: {len(val_data)} å¼µ\n",
    "- Batch size: {BATCH_SIZE}\n",
    "- Epochs: {NUM_EPOCHS}\n",
    "- é¡åˆ¥åŠ æ¬Š: æ˜¯\n",
    "\n",
    "## çµæœ\n",
    "| æŒ‡æ¨™ | æ•¸å€¼ |\n",
    "|------|------|\n",
    "| Accuracy | {val_acc:.4f} ({val_acc*100:.1f}%) |\n",
    "| AUC-ROC | {val_auc:.4f} |\n",
    "| Precision (è‘—åºŠ) | {precision_1:.4f} |\n",
    "| Recall (è‘—åºŠ) | {recall_1:.4f} |\n",
    "| F1-Score (è‘—åºŠ) | {f1_1:.4f} |\n",
    "\n",
    "## æ··æ·†çŸ©é™£\n",
    "- TN (çŒœå°ä¸è‘—åºŠ): {tn}\n",
    "- FP (èª¤å ±): {fp}\n",
    "- FN (æ¼æ‰): {fn}\n",
    "- TP (çŒœå°è‘—åºŠ): {tp}\n",
    "\n",
    "## èˆ‡ EXP-001 æ¯”è¼ƒ\n",
    "| æŒ‡æ¨™ | EXP-001 | EXP-002 | å·®ç•° |\n",
    "|------|---------|---------|------|\n",
    "| AUC | 0.7986 | {val_auc:.4f} | {val_auc - 0.7986:+.4f} |\n",
    "| Recall | 0.7600 | {recall_1:.4f} | {recall_1 - 0.76:+.4f} |\n",
    "| Precision | 0.5000 | {precision_1:.4f} | {precision_1 - 0.50:+.4f} |\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ ä¸‹ä¸€æ­¥å»ºè­°\n",
    "\n",
    "æ ¹æ“š EXP-002 çµæœï¼š\n",
    "\n",
    "1. **å¦‚æœ AUC æœ‰æå‡** â†’ EfficientNet ç¢ºå¯¦æ›´é©åˆé€™å€‹ä»»å‹™\n",
    "2. **å¦‚æœ AUC å·®ä¸å¤š** â†’ å¯ä»¥å˜—è©¦å…¶ä»–æ”¹é€²æ–¹å‘ï¼ˆFocal Lossã€æ›´å¼·çš„å¢å¼·ï¼‰\n",
    "3. **å¦‚æœ AUC ä¸‹é™** â†’ ResNet18 å¯èƒ½æ›´é©åˆï¼Œæˆ–éœ€è¦èª¿æ•´è¶…åƒæ•¸"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
