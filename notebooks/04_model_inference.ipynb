{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ¨¡å‹æ¨è«–ï¼ˆé æ¸¬æ–°è³‡æ–™ï¼‰\n",
    "\n",
    "> é€™å€‹ notebook ç”¨æ–¼è¼‰å…¥å·²è¨“ç·´å¥½çš„æ¨¡å‹ï¼Œå°æ–°çš„èƒšèƒç…§ç‰‡é€²è¡Œé æ¸¬\n",
    "\n",
    "## ä½¿ç”¨èªªæ˜\n",
    "\n",
    "1. ä¸Šå‚³è¨“ç·´å¥½çš„æ¨¡å‹æª”æ¡ˆ (`best_model.pth`)\n",
    "2. ä¸Šå‚³è¦é æ¸¬çš„èƒšèƒç…§ç‰‡ï¼ˆæ”¾åœ¨ä¸€å€‹è³‡æ–™å¤¾å…§ï¼‰\n",
    "3. åŸ·è¡Œæ‰€æœ‰ cell\n",
    "4. ä¸‹è¼‰é æ¸¬çµæœ CSV æª”æ¡ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: å®‰è£å’Œè¼‰å…¥å¥—ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# æª¢æŸ¥ GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'ä½¿ç”¨è£ç½®: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: ä¸Šå‚³æ¨¡å‹æª”æ¡ˆ\n",
    "\n",
    "è«‹ä¸Šå‚³ä½ å¾ EXP-001 è¨“ç·´å¥½çš„ `best_model.pth` æª”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸Šå‚³æ¨¡å‹æª”æ¡ˆ\n",
    "print(\"è«‹ä¸Šå‚³ best_model.pth æª”æ¡ˆ...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# ç¢ºèªä¸Šå‚³æˆåŠŸ\n",
    "model_path = list(uploaded.keys())[0]\n",
    "print(f\"\\nâœ… æ¨¡å‹æª”æ¡ˆå·²ä¸Šå‚³: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: è¼‰å…¥æ¨¡å‹\n",
    "\n",
    "è¼‰å…¥ EXP-001 ä½¿ç”¨çš„ ResNet18 æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹èˆ‡è¨“ç·´æ™‚ç›¸åŒçš„æ¨¡å‹æ¶æ§‹\n",
    "model = models.resnet18(weights=None)  # ä¸è¼‰å…¥é è¨“ç·´æ¬Šé‡\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # æ”¹æˆ 2 é¡è¼¸å‡º\n",
    "\n",
    "# è¼‰å…¥è¨“ç·´å¥½çš„æ¬Šé‡\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()  # è¨­ç‚ºè©•ä¼°æ¨¡å¼\n",
    "\n",
    "print(\"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: ä¸Šå‚³è¦é æ¸¬çš„ç…§ç‰‡\n",
    "\n",
    "è«‹å°‡æ‰€æœ‰è¦é æ¸¬çš„èƒšèƒç…§ç‰‡æ‰“åŒ…æˆ **zip æª”æ¡ˆ**ï¼Œç„¶å¾Œä¸Šå‚³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹å­˜æ”¾ç…§ç‰‡çš„è³‡æ–™å¤¾\n",
    "inference_dir = '/content/inference_images'\n",
    "if os.path.exists(inference_dir):\n",
    "    shutil.rmtree(inference_dir)\n",
    "os.makedirs(inference_dir)\n",
    "\n",
    "# ä¸Šå‚³ zip æª”æ¡ˆ\n",
    "print(\"è«‹ä¸Šå‚³åŒ…å«èƒšèƒç…§ç‰‡çš„ zip æª”æ¡ˆ...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# è§£å£“ç¸®\n",
    "zip_path = list(uploaded.keys())[0]\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(inference_dir)\n",
    "\n",
    "# æ‰¾å‡ºæ‰€æœ‰åœ–ç‰‡æª”æ¡ˆï¼ˆæ”¯æ´ jpg, jpeg, pngï¼‰\n",
    "image_extensions = ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']\n",
    "image_files = []\n",
    "\n",
    "for root, dirs, filenames in os.walk(inference_dir):\n",
    "    for filename in filenames:\n",
    "        if any(filename.endswith(ext) for ext in image_extensions):\n",
    "            image_files.append(os.path.join(root, filename))\n",
    "\n",
    "print(f\"\\nâœ… æ‰¾åˆ° {len(image_files)} å¼µåœ–ç‰‡\")\n",
    "print(\"\\nåœ–ç‰‡åˆ—è¡¨:\")\n",
    "for img in image_files[:10]:  # åªé¡¯ç¤ºå‰ 10 å¼µ\n",
    "    print(f\"  - {os.path.basename(img)}\")\n",
    "if len(image_files) > 10:\n",
    "    print(f\"  ... é‚„æœ‰ {len(image_files) - 10} å¼µ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: è¨­å®šåœ–ç‰‡é è™•ç†\n",
    "\n",
    "ä½¿ç”¨èˆ‡è¨“ç·´æ™‚ç›¸åŒçš„é è™•ç†æ–¹å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šç¾©åœ–ç‰‡é è™•ç†ï¼ˆèˆ‡è¨“ç·´æ™‚ç›¸åŒï¼‰\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "print(\"âœ… åœ–ç‰‡é è™•ç†è¨­å®šå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: é€²è¡Œé æ¸¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€²è¡Œé æ¸¬\n",
    "results = []\n",
    "\n",
    "print(\"é–‹å§‹é æ¸¬...\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_path in image_files:\n",
    "        # è¼‰å…¥ä¸¦é è™•ç†åœ–ç‰‡\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # é æ¸¬\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        \n",
    "        # å–å¾—ã€Œæœƒè‘—åºŠã€çš„æ©Ÿç‡ï¼ˆClass 1ï¼‰\n",
    "        prob_implant = probabilities[0][1].item()\n",
    "        \n",
    "        # é è¨­é–¾å€¼ 0.5 çš„é æ¸¬çµæœ\n",
    "        prediction = \"æœƒè‘—åºŠ\" if prob_implant >= 0.5 else \"ä¸æœƒè‘—åºŠ\"\n",
    "        \n",
    "        results.append({\n",
    "            'æª”æ¡ˆåç¨±': os.path.basename(img_path),\n",
    "            'è‘—åºŠæ©Ÿç‡': round(prob_implant, 4),\n",
    "            'é æ¸¬çµæœ(é–¾å€¼0.5)': prediction\n",
    "        })\n",
    "\n",
    "print(f\"âœ… å®Œæˆï¼å…±é æ¸¬ {len(results)} å¼µåœ–ç‰‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: æŸ¥çœ‹é æ¸¬çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹çµæœè¡¨æ ¼\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# æŒ‰è‘—åºŠæ©Ÿç‡æ’åºï¼ˆé«˜åˆ°ä½ï¼‰\n",
    "df_results = df_results.sort_values('è‘—åºŠæ©Ÿç‡', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# é¡¯ç¤ºçµæœ\n",
    "print(\"=\" * 60)\n",
    "print(\"é æ¸¬çµæœï¼ˆæŒ‰è‘—åºŠæ©Ÿç‡ç”±é«˜åˆ°ä½æ’åºï¼‰\")\n",
    "print(\"=\" * 60)\n",
    "display(df_results)\n",
    "\n",
    "# çµ±è¨ˆæ‘˜è¦\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"çµ±è¨ˆæ‘˜è¦\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ç¸½å…±é æ¸¬: {len(df_results)} å¼µ\")\n",
    "print(f\"é æ¸¬ã€æœƒè‘—åºŠã€: {(df_results['é æ¸¬çµæœ(é–¾å€¼0.5)'] == 'æœƒè‘—åºŠ').sum()} å¼µ\")\n",
    "print(f\"é æ¸¬ã€ä¸æœƒè‘—åºŠã€: {(df_results['é æ¸¬çµæœ(é–¾å€¼0.5)'] == 'ä¸æœƒè‘—åºŠ').sum()} å¼µ\")\n",
    "print(f\"\\nè‘—åºŠæ©Ÿç‡çµ±è¨ˆ:\")\n",
    "print(f\"  å¹³å‡: {df_results['è‘—åºŠæ©Ÿç‡'].mean():.4f}\")\n",
    "print(f\"  æœ€é«˜: {df_results['è‘—åºŠæ©Ÿç‡'].max():.4f}\")\n",
    "print(f\"  æœ€ä½: {df_results['è‘—åºŠæ©Ÿç‡'].min():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: ä¸‹è¼‰é æ¸¬çµæœ\n",
    "\n",
    "å°‡çµæœåŒ¯å‡ºç‚º CSV æª”æ¡ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å„²å­˜ç‚º CSV\n",
    "output_path = '/content/prediction_results.csv'\n",
    "df_results.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"âœ… çµæœå·²å„²å­˜ç‚º: {output_path}\")\n",
    "\n",
    "# ä¸‹è¼‰æª”æ¡ˆ\n",
    "files.download(output_path)\n",
    "print(\"\\nğŸ“¥ æª”æ¡ˆå·²é–‹å§‹ä¸‹è¼‰...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## é€²éšåŠŸèƒ½ï¼šèª¿æ•´åˆ¤æ–·é–¾å€¼\n",
    "\n",
    "å¦‚æœä½ æƒ³ç”¨ä¸åŒçš„é–¾å€¼ä¾†åˆ¤æ–·ï¼Œå¯ä»¥åŸ·è¡Œä¸‹é¢çš„ cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å˜—è©¦ä¸åŒé–¾å€¼\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "\n",
    "print(\"ä¸åŒé–¾å€¼ä¸‹çš„é æ¸¬çµæœï¼š\\n\")\n",
    "for threshold in thresholds:\n",
    "    count_implant = (df_results['è‘—åºŠæ©Ÿç‡'] >= threshold).sum()\n",
    "    count_not_implant = len(df_results) - count_implant\n",
    "    print(f\"é–¾å€¼ {threshold}: é æ¸¬ã€æœƒè‘—åºŠã€{count_implant} å¼µï¼Œã€ä¸æœƒè‘—åºŠã€{count_not_implant} å¼µ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚æœè¦ç”¨è‡ªè¨‚é–¾å€¼ç”¢ç”Ÿçµæœï¼Œä¿®æ”¹ä¸‹é¢çš„æ•¸å€¼\n",
    "custom_threshold = 0.4  # â† ä¿®æ”¹é€™è£¡\n",
    "\n",
    "df_results['é æ¸¬çµæœ(è‡ªè¨‚é–¾å€¼)'] = df_results['è‘—åºŠæ©Ÿç‡'].apply(\n",
    "    lambda x: 'æœƒè‘—åºŠ' if x >= custom_threshold else 'ä¸æœƒè‘—åºŠ'\n",
    ")\n",
    "\n",
    "print(f\"ä½¿ç”¨é–¾å€¼ {custom_threshold} çš„çµæœï¼š\\n\")\n",
    "display(df_results)\n",
    "\n",
    "# å„²å­˜è‡ªè¨‚é–¾å€¼çµæœ\n",
    "output_path_custom = f'/content/prediction_results_threshold_{custom_threshold}.csv'\n",
    "df_results.to_csv(output_path_custom, index=False, encoding='utf-8-sig')\n",
    "files.download(output_path_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## å‚™è¨»\n",
    "\n",
    "- é€™å€‹é æ¸¬çµæœæ˜¯åŸºæ–¼ **EXP-001 (ResNet18)** æ¨¡å‹\n",
    "- æ¨¡å‹çš„ Recall ç‚º 76%ï¼Œè¡¨ç¤ºçœŸæ­£æœƒè‘—åºŠçš„èƒšèƒï¼ŒAI æœ‰ 76% æ©ŸæœƒçŒœå°\n",
    "- æ¨¡å‹çš„ Precision ç‚º 50%ï¼Œè¡¨ç¤º AI èªªã€Œæœƒè‘—åºŠã€çš„ï¼Œæœ‰ 50% æ˜¯çœŸçš„æœƒè‘—åºŠ\n",
    "- **å› ç‚ºé€™æ‰¹è³‡æ–™æ²’æœ‰å¯¦éš›æ¨™ç±¤ï¼Œæ‰€ä»¥åªèƒ½å¾—åˆ°é æ¸¬çµæœï¼Œç„¡æ³•è¨ˆç®—æº–ç¢ºç‡**\n",
    "- ç­‰ä¹‹å¾ŒçŸ¥é“å¯¦éš›çµæœå¾Œï¼Œå¯ä»¥å›ä¾†é©—è­‰æ¨¡å‹é æ¸¬çš„æº–ç¢ºåº¦"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
