# 實驗結果記錄（簡易版）

> 這份文件記錄每次訓練 AI 的結果，用簡單易懂的方式呈現

---

## 結果總覽

| 實驗 | 日期 | 用什麼資料 | AI 模型 | 準確率 | AUC | 會著床的猜對率 | 備註 |
|------|------|-----------|---------|--------|-----|--------------|------|
| EXP-001_example | 2025-01-25 | v1.0 範例 | ResNet18 | 85.7% | 0.72 | 36% | ⚠️ 範例 |
| EXP-001 | | | | | | | 待執行 |

### 指標說明
- **準確率**：整體猜對多少（但資料不平衡時會騙人！）
- **AUC**：模型分辨能力（0~1，越高越好）
- **會著床的猜對率 (Recall)**：真正會著床的胚胎，AI 猜對幾成 ← **最重要！**

---

## 目前最好的模型

| 排名 | 實驗編號 | AUC | 會著床猜對率 | 備註 |
|------|----------|-----|-------------|------|
| 1 | | | | |
| 2 | | | | |
| 3 | | | | |

---

## 詳細實驗記錄

---

### EXP-001_example ⚠️ 這是範例

> 這是展示用的範例，讓大家知道記錄長什麼樣子

**基本資訊**
| 項目 | 內容 |
|------|------|
| 日期 | 2025-01-25 |
| 執行者 | （範例）王小明 |
| 目標 | 建立最基本的模型，看看效果如何 |

**用了什麼資料**
| 項目 | 內容 |
|------|------|
| 資料版本 | v1.0_baseline_example |
| 訓練照片 | 672 張 |
| 驗證照片 | 168 張 |

**AI 設定（簡化版）**
| 設定 | 內容 | 說明 |
|------|------|------|
| 模型 | ResNet18 | 一種常用的圖像辨識 AI |
| 訓練次數 | 50 輪 | AI 看過全部照片 50 遍 |
| 預訓練 | 有 | AI 已經先學過其他照片 |

**結果**

| 指標 | 數值 | 好不好？ |
|------|------|---------|
| 準確率 | 85.7% | 看起來還行，但其實是假象 |
| AUC | 0.72 | 普通，有進步空間 |
| **會著床的猜對率** | **36%** | **不好！很多會著床的沒猜到** |
| 會著床的猜對精準度 | 45% | 不好！猜會著床的常猜錯 |

**預測結果分析**

```
在 168 張驗證照片中：

實際不會著床的 143 張：
  → AI 猜對 135 張 ✓
  → AI 猜錯 8 張 ✗ （誤以為會著床）

實際會著床的 25 張：
  → AI 猜對 9 張 ✓
  → AI 猜錯 16 張 ✗ （漏掉了！這是大問題）
```

**學到什麼**

1. **大問題**：AI 太保守了
   - 幾乎都猜「不會著床」
   - 因為訓練資料裡 85% 都是不會著床的

2. **為什麼準確率會騙人**
   - 如果 AI 全部猜「不會著床」，準確率也有 85%
   - 但這樣完全沒用！

3. **下次要改進的方向**
   - 讓 AI 更重視「會著床」的照片
   - 或是增加「會著床」照片的數量

---

### EXP-001：（實驗名稱）

**基本資訊**
| 項目 | 內容 |
|------|------|
| 日期 | |
| 執行者 | |
| 目標 | |

**用了什麼資料**
| 項目 | 內容 |
|------|------|
| 資料版本 | |
| 訓練照片 | |
| 驗證照片 | |

**結果**
| 指標 | 數值 | 好不好？ |
|------|------|---------|
| 準確率 | | |
| AUC | | |
| 會著床的猜對率 | | |

**學到什麼**

1.

2.

---

## 實驗心得總結

### 有效的方法
（記錄哪些嘗試讓結果變好）
-

### 沒效的方法
（記錄哪些嘗試沒用，避免重複踩坑）
-

### 重要發現
-
